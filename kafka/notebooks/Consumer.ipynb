{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2679d27",
   "metadata": {},
   "source": [
    "# Kafka Consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1fd007",
   "metadata": {},
   "source": [
    "Using the `kafka-python` module, Kafka consumers can be instantiated via the `KafkaConsumer` class:\n",
    "\n",
    "```python\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "# Create a Kafka consumer instance\n",
    "consumer = KafkaConsumer(\n",
    "    bootstrap_servers=['62.30.10.23:9092'],  # list of brokers\n",
    "    security_protocol=\"SSL\",                 # security protocol (if any) \n",
    "    ssl_cafile=\"./ca.pem\",                   # certificate details (if any)\n",
    "    ssl_certfile=\"./service.cert\",           #           ...\n",
    "    ssl_keyfile=\"./service.key\",             #           ...\n",
    "    value_deserializer=msgpack.unpackb,      # message value deserialization function (e.g. unpack the message from a specific format)\n",
    "    auto_offset_reset='earliest',            # automatically bring the reading offset to the earliest message\n",
    "    group_id=\"group_A\",                      # identify this consumer as part of group_A\n",
    ")\n",
    "```\n",
    "\n",
    "Once more, we'll use a simple implementation of the consumer, with no specific configurations used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9babe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of brokers in the cluster\n",
    "KAFKA_BOOTSTRAP_SERVERS = ['kafka-broker:9092']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "# create a Kafka consumer instance\n",
    "consumer = KafkaConsumer(\n",
    "    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,  # list of Kafka brokers\n",
    "    consumer_timeout_ms=10000                   # maximum time to wait for a new message \n",
    "                                                # before stopping the consumer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d27c9",
   "metadata": {},
   "source": [
    "Inspect the available topics on the brokers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all available topics on the kafka brokers\n",
    "consumer.topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9fe31",
   "metadata": {},
   "source": [
    "In the Publish/Subscribe (Pub/Sub) model, before consuming messages from a specific topic, you need to subscribe to that topic. By subscribing, the consumer expresses its interest in receiving messages from the specified topic.\n",
    "\n",
    "It's important to note that subscribing to a topic doesn't immediately consume any messages. \n",
    "\n",
    "Instead, it establishes a connection between the consumer and the partitions of the subscribed topic hosted on the Kafka brokers. This connection allows the consumer to start polling for messages from those partitions.\n",
    "\n",
    "Once you have subscribed to the topic, the consumer can start polling for messages, fetching messages from the subscribed partitions and return them to the consumer for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscribe to a topic\n",
    "consumer.subscribe('my_awesome_topic')\n",
    "\n",
    "# check the active subscriptions\n",
    "consumer.subscription()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9745516",
   "metadata": {},
   "source": [
    "The `KafkaConsumer` class also offers the possibility to inspect topics (for instance, in terms of the number of partitions), but **not** to modify them. \n",
    "\n",
    "We can inspect how many partitions the specific topic is made of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of partition IDs \n",
    "# e.g. a topic with tree partitions will have partition IDs {0, 1, 2}\n",
    "consumer.partitions_for_topic('my_awesome_topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac50e4a",
   "metadata": {},
   "source": [
    "We can instruct the consumer to `poll` (i.e., ask for all new messages stored in the topic) with a given cadence or logic.\n",
    "\n",
    "For instance, we can set the consumer to read only 10 messages at a time, with a timeout between subsequent readouts of a given $\\Delta t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211359b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the polling strategy for the consumer\n",
    "consumer.poll(timeout_ms=0,         # do not enable dead-times before one poll to the next\n",
    "              max_records=None,     # do not limit the number of records to consume at once \n",
    "              update_offsets=True   # update the reading offsets on this topic\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b87dec",
   "metadata": {},
   "source": [
    "Now the consumer is ready to poll messages (until it is stopped or it reaches a timeout).\n",
    "\n",
    "Let's look for all messages in the consumer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this consumer will keep polling for messages \n",
    "# until stopped by the user\n",
    "# (or reaches the consumer_timeout_ms, if specified)\n",
    "for message in consumer:\n",
    "    print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a7a25",
   "metadata": {},
   "source": [
    "The reading offset can also be reset to the beginning of the topic, allowing for re-reading the entire topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443dae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# go back to the beginning of the topic\n",
    "consumer.seek_to_beginning()\n",
    "\n",
    "# read the entire topic and print it out\n",
    "for message in consumer:\n",
    "    print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc220cc1",
   "metadata": {},
   "source": [
    "The message content (`ConsumerRecord`) can be quite messy, but it can be easily inspected by parsing only the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages to interpret dates\n",
    "from datetime import datetime\n",
    "\n",
    "# go back to the beginning of the topic\n",
    "consumer.seek_to_beginning()\n",
    "\n",
    "# break down the message into its main components\n",
    "for message in consumer:\n",
    "    print (\"%d[%d] @%s k=%s v=%s\" % (message.partition,\n",
    "                          message.offset,\n",
    "                          datetime.fromtimestamp(message.timestamp/1000).time(),\n",
    "                          message.key,\n",
    "                          message.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9186d",
   "metadata": {},
   "source": [
    "Let's change the topic to which the consumer is subscribed and make it a partitioned one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscribe to a partitioned topic\n",
    "consumer.subscribe('a_partitioned_topic')\n",
    "consumer.subscription()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38f95e",
   "metadata": {},
   "source": [
    "By inspecting the number of partitions for this topic, we can now see that there are 2 partitions: partition #0 and partition #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the partitions in the partitioned topic\n",
    "consumer.partitions_for_topic('a_partitioned_topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c87793",
   "metadata": {},
   "source": [
    "When reading from a partitioned topic, it's easy to observe that the messages are sent to the two partitions in a seemingly arbitrary way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json to unpack json strings\n",
    "import json\n",
    "\n",
    "# go back to the beginning of the topic\n",
    "consumer.seek_to_beginning()\n",
    "\n",
    "# read messages from the beginning of the topic\n",
    "# decode the json into the python dictionary format\n",
    "for message in consumer:\n",
    "    print(f\"{message.partition}[{message.offset}]\\t {json.loads(message.value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd766d",
   "metadata": {},
   "source": [
    "## Creating a Consumer Accessing Only One Partition\n",
    "\n",
    "Publishing records to a partitioned topic is typically transparent to the user: the producer publishes to the topic, and the Kafka cluster will redirect the message to the partition leader, later replicating it to the followers.\n",
    "\n",
    "The same applies to a generic consumer. As we have just seen, data is consumed from all partitions within the topic.\n",
    "\n",
    "In some cases, however, it may be more suitable to instantiate multiple consumers, with each one reading from a specific partition of a topic.\n",
    "\n",
    "Let's create a consumer specifically designed to access the data from partition #0 of the previous partitioned topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import TopicPartition to be able to assign a partition to a consumer\n",
    "from kafka import TopicPartition\n",
    "\n",
    "# create a standard consumer with a timeout of 10 seconds\n",
    "consumer_part_0 = KafkaConsumer(bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,\n",
    "                                client_id='consumer_n_0',\n",
    "                                consumer_timeout_ms=10000)\n",
    "\n",
    "# assign the consumer to a specific topic-partition combination\n",
    "consumer_part_0.assign([TopicPartition(topic     = 'a_partitioned_topic', # topic\n",
    "                                       partition = 0                      # partition id\n",
    "                                      )]\n",
    "                      ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefaba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to the beginning of the topic (for this specific partition)\n",
    "consumer_part_0.seek_to_beginning()\n",
    "\n",
    "# read messages from the beginning of the topic (for this specific partition)\n",
    "# decode the json into the python dictionary format\n",
    "for message in consumer_part_0:\n",
    "    print(f\"{message.partition}[{message.offset}]\\t {json.loads(message.value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e776c",
   "metadata": {},
   "source": [
    "## Creating a Consumer Group\n",
    "\n",
    "Multiple consumers can read from the same topic.\n",
    "\n",
    "In Kafka, every consumer is part of a consumer group (even a single consumer is part of its own consumer group).\n",
    "\n",
    "A consumer group consists of one or more cooperating consumers that gather data from the same topic. The consumer group dynamically balances the load across its members and redistributes the consume calls.\n",
    "\n",
    "If a consumer within a consumer group fails, the remaining consumers in the same group will continue to read the entire data from the subscribed topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca71af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create `consumer_one` to read from a specific partition\n",
    "# assign this consumer to a group\n",
    "consumer_one = KafkaConsumer(bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,\n",
    "                             client_id='consumer_one',\n",
    "                             group_id='my_group',                       # the same group will be used by all consumers\n",
    "                             auto_offset_reset='earliest',\n",
    "                             consumer_timeout_ms=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import ConsumerRebalanceListener\n",
    "\n",
    "# subscribe `consumer_one` to the partitioned topic\n",
    "consumer_one.subscribe('a_partitioned_topic',\n",
    "                       listener=ConsumerRebalanceListener()             # set a logic on how the group should be re-balance \n",
    "                                                                        # when partitions are added or removed\n",
    "                                                                        # or when new consumers are assigned to partitions\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd55dbc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Consuming messages as a group\n",
    "Use the `ConsumerGroup` notebook to:\n",
    "1. create a second consumer `consumer_two`\n",
    "2. assign it to the same consumer group `my_group`\n",
    "3. subscribe to the same topic `a_partitioned_topic`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f527b",
   "metadata": {},
   "source": [
    "Each consumer within a group is going to be an independent process (should be run in parallel from the others) and will provide access to a fraction of the incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7960448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the partitions assigned to `consumer_one`\n",
    "consumer_one.assignment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552330d",
   "metadata": {},
   "source": [
    "Start the two consumers and process data in parallel from the two partitions.\n",
    "\n",
    "Typically, one would achieve this by running the two consumers in separate threads, processes, or executors, depending on the desired computing architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multiple consumers in parallel (`consumer_one` in this notebook)\n",
    "for message in consumer_one:\n",
    "    print(f\"{message.partition}[{message.offset}]\\t {json.loads(message.value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c771db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reading from the Kafka+Spark results topic\n",
    "\n",
    "Let's subscribe to the `results` topic and monitor the frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c33193",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.subscribe('results')\n",
    "\n",
    "for message in consumer:\n",
    "    print (\"%d[%d] k=%s v=%s\" % (message.partition,\n",
    "                          message.offset,\n",
    "                          message.key,\n",
    "                          message.value))\n",
    "    print ('      --> sending alert message to user {}\\n'.format(message.key.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a448c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
